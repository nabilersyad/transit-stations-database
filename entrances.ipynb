{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Transit Station Entrances in Klang Valley with Overpass API and Python\n",
    "\n",
    "In this notebook, we will explore the locations of subway entrances within Klang Valley using data from OpenStreetMap (OSM). \n",
    "\n",
    "We will leverage the Overpass API, a read-only API that allows access to OSM data. Specifically, we will use Overpass' powerful querying capabilities to identify nodes tagged as `subway_entrance` within the boundary of Malaysia.\n",
    "\n",
    "Once we have collected the subway entrances, we will then identify which public transport stations these entrances are associated with. To achieve this, we will query OSM relations tagged as `public_transport`.\n",
    "\n",
    "The data will be processed and stored in a pandas DataFrame, enabling us to manipulate and analyze the data easily.\n",
    "\n",
    "The ultimate goal is to create a table of subway entrances, complete with their coordinates and associated station names, providing a clear understanding of the distribution of subway entrances across Malaysia.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Overpass API and variables\n",
    "\n",
    "We will initialize two dataframes which will be used to create two tables down the line\n",
    "*entrance* - Which will hold details and characteristics of each individual entrance. This includes coordinates and destinations\n",
    "*station_entrances* - Will track the relationship between each entrance and station.\n",
    "\n",
    "The creation of two tables is to handle the many-to-many relationship between entrances and train stations. One station can have many entrances. While one entrance can lead to many stations\n",
    "\n",
    "For example Entrance A of MRT Kajang is also an entrance to KTM Kajang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import overpy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# initialize Overpass API\n",
    "api = overpy.Overpass()\n",
    "\n",
    "# DataFrames for entrances and station-entrance relationships\n",
    "entrances = pd.DataFrame(columns=['Entrance ID', 'Longitude','Latitude','Entrance Destination'])\n",
    "station_entrances = pd.DataFrame(columns=['Relationship ID', 'Entrance ID', 'Station ID','Station Name'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Subway Entrances in Malaysia\n",
    "\n",
    "We use the api.query() function to send a query to the Overpass API. This query searches within the administrative boundary of Malaysia for nodes that are tagged as subway_entrance in OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Query all subway entrances in Malaysia\n",
    "result_entrances = api.query(\"\"\"\n",
    "[out:json][timeout:25];\n",
    "area[\"name\"=\"Malaysia\"][\"boundary\"=\"administrative\"]->.searchArea;\n",
    "node[\"railway\"~\"subway_entrance|train_station_entrance\"](area.searchArea);\n",
    "out body;\n",
    "\"\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Subway Entrance IDs and Coordinates\n",
    "\n",
    "We loop through the nodes returned by our query, which represent subway entrances, and add their ID and coordinates to our entrances list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store the subway_entrance object IDs and coordinates in df_entrances\n",
    "for node in result_entrances.nodes:\n",
    "    entrances = pd.concat(\n",
    "        [entrances, \n",
    "         pd.DataFrame([{'Entrance ID': node.id, \n",
    "                        'Entrance Name':node.tags.get('ref'),\n",
    "                        'Entrance Destination':node.tags.get('destination'),\n",
    "                        'Longitude':node.lon,\n",
    "                        'Latitude':node.lat}])], \n",
    "        ignore_index=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Public Transport Relations in Malaysia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query all relations in Malaysia\n",
    "result_relations = api.query(\"\"\"\n",
    "[out:json][timeout:25];\n",
    "area[\"name\"=\"Malaysia\"][\"boundary\"=\"administrative\"]->.searchArea;\n",
    "relation[\"type\"=\"public_transport\"](area.searchArea);\n",
    "out body;\n",
    "> ;\n",
    "out skel qt;\n",
    "\"\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Subway Entrances to Public Transport Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Entrance ID    Longitude   Latitude    Entrance Destination Entrance Name\n",
      "0     1544031348  101.7113737  3.1459286                    None             B\n",
      "1     1631412559  101.6049519  3.1132222                    None          None\n",
      "2     2278515570  101.6440770  3.0506498                    None          None\n",
      "3     2686635178  101.6991821  3.1385646                    None             C\n",
      "4     3308608988  101.7127175  3.1587619                    None          None\n",
      "..           ...          ...        ...                     ...           ...\n",
      "219  10949038884  101.6814387  3.2377790                    None          None\n",
      "220  11033916949  101.5939259  3.1494167  Tropicana Gardens Mall          None\n",
      "221  11039579993  101.6933961  3.1667580       Sunway Putra Mall          None\n",
      "222  11039579994  101.6937307  3.1670090                Chow Kit          None\n",
      "223  11039725697  101.6962758  3.1493952                    None          None\n",
      "\n",
      "[224 rows x 5 columns]\n",
      "    Relationship ID  Entrance ID Station ID             Station Name\n",
      "0                 0  10796851698  AG10;SP10                     Pudu\n",
      "1                 1   5485710279       KJ11             Kampung Baru\n",
      "2                 2   5485710278       KJ11             Kampung Baru\n",
      "3                 3   9740843587       KJ13        Masjid Jamek (KJ)\n",
      "4                 4   9983121350       KJ13        Masjid Jamek (KJ)\n",
      "..              ...          ...        ...                      ...\n",
      "224             224  10839997852       PY39          Cyberjaya Utara\n",
      "225             225  10658294223       PY30    Cyberjaya City Centre\n",
      "226             226  10722980582       PY41  Putrajaya Sentral (MRT)\n",
      "227             227   5044809585       PY23  Tun Razak Exchange (PY)\n",
      "228             228   5044809586       PY23  Tun Razak Exchange (PY)\n",
      "\n",
      "[229 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# For each relation, check if it contains any of our entrances\n",
    "relationship_id = 0\n",
    "for relation in result_relations.relations:\n",
    "    station_id = relation.tags.get('ref', 'Unnamed')\n",
    "    station_name = relation.tags.get('name', 'Unnamed')\n",
    "    for member in relation.members:\n",
    "        if member.ref in entrances['Entrance ID'].values:\n",
    "            station_entrances = pd.concat(\n",
    "                [station_entrances,\n",
    "                 pd.DataFrame([{'Relationship ID': relationship_id, \n",
    "                                'Entrance ID': member.ref,\n",
    "                                'Station Name': station_name, \n",
    "                                'Station ID': station_id}])], \n",
    "                ignore_index=True\n",
    "            )\n",
    "            relationship_id += 1\n",
    "\n",
    "print(entrances)\n",
    "print(station_entrances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Found Dataset\n",
    "Finally, we will save the found entrances dataset to a new CSV file for use in creating our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where you want to save the cleaned data\n",
    "data_directory = 'data'\n",
    "kl_entrances_file = 'klang_valley__entrances.csv'\n",
    "kl_entrances__station_relations = 'klang_valley_stations_entrances_relation.csv'\n",
    "\n",
    "\n",
    "# Save the cleaned dataframes\n",
    "entrances.to_csv(os.path.join(data_directory, kl_entrances_file), index=False)\n",
    "station_entrances.to_csv(os.path.join(data_directory, kl_entrances__station_relations), index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "We're aware that there are gaps in the data. Not all entrances are available and mapped in OSM. Addtional entrances must be added manually for a more complete dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c2c577300a283823fdaa3bb6febf40791e267aabde0cafde1043d84c9a16083"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
